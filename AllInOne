import cv2
import mediapipe as mp
import pyaudio
import speech_recognition as sr
from GoogleNews import GoogleNews
from google_trans_new import google_translator
import pyttsx3

cascade1=cv2.CascadeClassifier("C:/Users/Sreemayi Dontha/PycharmProjects/pythonProject4/venv/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml")
cascade2=cv2.CascadeClassifier("C:/Users/Sreemayi Dontha/PycharmProjects/pythonProject4/venv/Lib/site-packages/cv2/data/haarcascade_eye_tree_eyeglasses.xml")

    #image1=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
def face_detection():
    camera=cv2.VideoCapture(0)
    while True:
        frame=camera.read()[1]
        f = cascade1.detectMultiScale(frame, 1.3, 3)
        for (x, y, w, h) in f:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)
            cv2.imshow("read",frame)
        if cv2.waitKey(1) & 0xFF==ord('v'):
            break
    camera.release()
    cv2.destroyAllWindows()
    waking()
def eye_detection():
    camera = cv2.VideoCapture(0)
    while True:
        frame = camera.read()[1]
        image=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
        """f = cascade1.detectMultiScale(image, 1.3, 3)
        for (x, y, w, h) in f:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)
            r=image[y:y+h,x:x+w]
            r1=frame[y:y+h,x:x+w]"""
        f = cascade2.detectMultiScale(image)
        for (x1, y1, w1, h1) in f:
            cv2.rectangle(frame, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 3)
            cv2.imshow("read", frame)
        if cv2.waitKey(1) & 0xFF == ord('v'):
            break
    camera.release()
    cv2.destroyAllWindows()
    waking()
def motion_detection():
    camera=cv2.VideoCapture(0)
    frame1=None
    while True:
        frame=camera.read()[1]
        g=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
        g=cv2.GaussianBlur(g,(21,21),0)
        if frame1 is None:
            frame1=g
            continue
        bf=cv2.absdiff(frame1,g)
        t=cv2.threshold(bf,25,255,cv2.THRESH_BINARY)[1]
        t=cv2.dilate(t,None,iterations=2)
        c,_=cv2.findContours(t.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
        for c1 in c:
            if cv2.contourArea(c1)>700:
                x,y,w,h =cv2.boundingRect(c1)
                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,0),3)
                fourcc=cv2.VideoWriter_fourcc(*'MPEG')
        cv2.imshow("img",frame)
        #out = cv2.VideoWriter('s3.mp4', fourcc, 20.0, (720, 1020))
        #out.write(frame)
        if cv2.waitKey(1) & 0xFF==ord('v'):
            break
    camera.release()
    cv2.destroyAllWindows()
    waking()
def hand_tracking():
    mp_drawing = mp.solutions.drawing_utils
    mp_drawing_styles = mp.solutions.drawing_styles
    mp_hands = mp.solutions.hands

    cap = cv2.VideoCapture(0)
    hands=mp_hands.Hands()
    while True:
        success, image = cap.read()
        # Flip the image horizontally for a later selfie-view display, and convert
        # the BGR image to RGB.
        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)
        # To improve performance, optionally mark the image as not writeable to
        # pass by reference.
        results = hands.process(image)
        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:                                                                         
                mp_drawing.draw_landmarks(image,hand_landmarks,mp_hands.HAND_CONNECTIONS)
        cv2.imshow('MediaPipe Hands', image)
        if cv2.waitKey(1) &0xFF==ord('v'):
            break
    cap.release()
    cv2.destroyAllWindows()
    waking()
def speech_reg():
    recognizer=sr.Recognizer()
    engine = pyttsx3.init()
    with sr.Microphone() as source: 
        print('Clearing background noise...')
        recognizer.adjust_for_ambient_noise(source,duration=3)
        print('Waiting for message..') 
        audio = recognizer.listen(source,timeout=3)
        print('Done recording..') 
    try:
        print('Recognizing..')
        result = recognizer.recognize_google(audio,language='en')
        result=result.lower()
        print('Your message:',format(result))
    except Exception as ex:
        print(ex)
    def trans():
        langinput=input('Type the language you want to convert:')
        translator = google_translator()  
        translate_text = translator.translate(str(result),lang_tgt=str(langinput))  
        print(translate_text)
        engine.say(str(translate_text))
        engine.runAndWait()
    trans()
    waking()
def ai_news():
    googlenews = GoogleNews()
    engine=pyttsx3.init()
    voices=engine.getProperty('voices')
    engine.setProperty('voice',voices[1].id)
    recognizer=sr.Recognizer()

    #Commands
    def cmd():
        with sr.Microphone() as source:
            print("Clearing background noises...Please wait")
            recognizer.adjust_for_ambient_noise(source,duration=1)
            print('Ask me anything..')
            recordedaudio=recognizer.listen(source,timeout=1)
            print("Done recording..!")
        try:
            text=recognizer.recognize_google(recordedaudio,language='en_US')
            text=text.lower()
            print('Your message:',format(text))

        except Exception as ex:
            print(ex)

        if 'headlines' in text:
            engine.say('Getting news for you ')
            engine.runAndWait()
            googlenews.get_news('Today news')
            googlenews.result()
            a=googlenews.gettext()
            print(*a[1:5],sep=',')
            engine.say(str(a[1:5]))
            engine.runAndWait()

        if 'tech' in text:
            engine.say('Getting news for you ')
            engine.runAndWait()
            googlenews.get_news('Tech')
            googlenews.result()
            a=googlenews.gettext()
            print(*a[1:5],sep=',')
            engine.say(str(a[1:5]))
            engine.runAndWait()

        if 'politics' in text:
            engine.say('Getting news for you ')
            engine.runAndWait()
            googlenews.get_news('Politics')
            googlenews.result()
            a=googlenews.gettext()
            print(*a[1:5],sep=',')
            engine.say(str(a[1:5]))
            engine.runAndWait()

        if 'sports' in text:
            engine.say('Getting news for you ')
            engine.runAndWait()
            googlenews.get_news('Sports')
            googlenews.result()
            a=googlenews.gettext()
            print(*a[1:5],sep=',')
            engine.say(str(a[1:5]))
            engine.runAndWait()

        if 'cricket' in text:
            engine.say('Getting news for you ')
            engine.runAndWait()
            googlenews.get_news('cricket')
            googlenews.result()
            a=googlenews.gettext()
            print(*a[1:5],sep=',')
            engine.say(str(a[1:5]))
            engine.runAndWait()
    cmd()
    waking()

def waking():
    print("1.FACE DETECTION")
    print("2.EYE DETECTION")
    print("3.INSTANCE MOTION DETECTION")
    print("4.HAND TRACING")
    print("5.SPEECH RECOGNTION")
    print("6.AI NEWS")
    print("7.EXIT")
    i=int(input())
    if i==1:
        face_detection()
    elif i==2:
        eye_detection()
    elif i==3:
        motion_detection()
    elif i==4:
        hand_tracking()  
    elif i==5:
        speech_reg()
    elif i==6:
        ai_news()
    elif i==7:
        exit()

        
waking()
